こんにちは。私は前川としきです。
私はチャンドラセカールプロジェクトで自然言語処理や理解について研究しています。
チャンドラセカールプロジェクトは科学クラブの中の一つです。
でははじめに、この文章を見てください。"How will the weather be?"
どうでしょうか。人間のみなさんなら、この文章が何を言いたいのかわかりますよね。
ですが、コンピューターにとってはとてもむずかしい問題です。
なぜなら、コンピューターにとってはただの文字列であって、なにか意味があるわけではないからです。
近年、コンピューターはとても発展し、画像認識や音声認識の分野では一般人でもわかるような大きな成果をあげています。


自動運転や音声入力などがいい例となるでしょう。
自然言語の分野ではどうでしょうか？みなさんは Siri や Google Assistant などの人工知能アシスタントを知っていますか？
それらを使ったことがある人はわかると思いますが、それらはちょっとむずかしい質問をするだけで意味理解を諦めてしまいます。
これを見て私は、どうにかならないだろうか、と思いました。
これが、私がコンピューターに文章の内容を汲み取らせるさせる研究を始めたきっかけです。
それではこれから、私がどのようにコンピューターに文章の意味を汲み取らせたかの説明をします。
まず、コンピューターにとって自然言語の意味抽出が難しい理由としては、曖昧な文法があります。
コンピューター用のプログラミング言語にも、人間の使う自然言語にも、同じように文法というものは存在しています。

しかし、それらには決定的な違いがあります。それは前述の通り、曖昧さの有無です。
この曖昧な文法を含む言語の理解が、人間も完全に可能なわけではありませんが、殆どの場合は問題にはなりません。
なぜ人間がこのような言語を使うことができるのかは完全に明らかになっているわけではありません。
しかし、文法が存在しているということは、コンピューターにも扱うことができるというわけです。
実際、近年の機械翻訳の精度は上がってきています。
あまり使ったことがない人は、過度な期待をせずに使ってみてください。思ったよりは有用であることに気づくはずです。
私はこの研究でコンピューターに、自然言語で書かれた文章と意味を表す形式言語を学習させました。
ですが、形式言語と言ってもよくわからないと思うので簡単に説明します。

スライドを見てください。
形式言語というよりも、命令群のようなものかもしれません。
例えば、weather n はn日後の天気を表しています。
他にもいろいろとあります。
この例では、同じ色の部分は同じ意味を表しています。
コンピューターは、このような意味を表す形式言語を生成します。
では、どのようにすればコンピューターは文章から意味を抽出できるのでしょうか。
近年、いわゆる人工知能が発展してきていますが、それは"Deep Learning"という技術のおかげです。
Deep Learningの解説の前に、まずはニューラルネットワークの説明をします。
ニューラルネットワークというのは、脳の神経回路を模した任意の関数を近似することができる技術です。
ニューラルネットワークはパーセプトロンがたくさん集まった構造をしています。
図のX1, X2, X3は入力、W1, W2, W3は重み、Yは出力と呼ばれています。

それぞれの入力にそれぞれの重みを掛けたものの総和が出力となります。
そしてその出力を期待していた出力と比較し誤差を修正します。
これがニューラルネットワークの学習の流れです。
特に階層型ニューラルネットワークというものでは、内部構造が入力層・中間層・出力層の３つに分かれています。
勘のいい人ならわかったかもしれませんが、Deep LearningのDeepというのは層が深い、つまり中間層が複数存在しているということです。
中間層が多くなると、計算量が膨大なるなどの問題があり、あまり使われてきませんでした。


しかし、コンピューターの性能向上により、膨大な計算が必要なDeep Learningが実用的なものになりました。
Deep Learningにより、より高度なことを扱えるようになり、以降、人工知能は発展を続けています。
今回、私がコンピューターに文章の意味の抽出させるために使ったリカレントニューラルネットワークというものも、Deep Learningの一種です。
リカレントニューラルネットワークは、ニューラルネットワークで時系列データの学習を行えるようにしたものです。
そして私は、リカレントニューラルネットワークの中でも特に Seq-to-Seq Model と呼ばれるものを利用しました。
近年は機械翻訳などに利用されていることで有名です。
先ほど説明した形式言語と自然言語の文章をこのモデルに学習させて、
自然言語を入力すると、正しい形式言語を出力するようにします。
ですがこのモデルには欠点があります。
それは、長い入力に対しての学習が苦手だということです。
この欠点を補うために、Attention Mechanism を利用しました。
これは、入力と出力の部分ごとの対応を学習させるためのものです。
これにより、学習の精度が向上します。

さて、今回コンピューターに学習させた文章は主に、皆さんが人工知能アシスタントに問うであろうものです。
例えば、天気はどう？とか明日の予定を教えて。などの内容の限られたものです。
ですが、肝心の文章があまり多く用意することが来ませんでした。
合わせて意味のリストを手作業で作らなければならなかったからです。
そういうわけで、今回は約40ほどの文章を学習させました。
もしかしたら、少ないと思われるかもしれません。確かに十分ではないかもしれません。
が、目的にあった文章を大量に用意するのは大変ですし、
コンピューターの学習にもかなりの時間がかかります。
これは次の研究にむけての課題と言えるかもしれません。
さて、ここからは研究で得られた結果を話していきます。
私は、学習させたコンピューターに20の新しい文章を入力し、
期待した出力をしたものの数を数えました。
すると、20個中13個が正しいものでした。
学習させたコンピューターに認識させた文章のいくつかを示します。（スライドを見せながら）
他にも認識に正解した例・失敗した例はありますが、良い例だと思ったのでこれらにしました。
見てみると、'how will the weather be' などのデータセットに含まれている文章は、当たり前ですが正しく認識されています。
データセットに含まれていないものも、いくつかはきちんと認識されています。
コンピューターがきちんと学習できている証拠です。
一方、正しく認識されなかったものもあります。
'can you tell me how the weather is' などです。
ですが、'tell me how the weather will be' は正しく認識されています。
何が言いたいのかというと、まず、'can you tell me how the weather is' と'tell me how the weather will be' は 'tell me how the weather' が共通しています。
そして、その共通している部分に意味の大半が集中しています。
これはコンピューターが、文章のどの部分に文章の意味が集中しているかということを学習できなかったということです。
もっと多くの文章を用意することができれば、より意味理解の精度が高まったことでしょう。
しかし、まだほかにも問題はあると思います。
人間、特に子供はわざわざ意味を教えてもらわなくとも自然に言葉を学習していきます。
しかしながら今回、私はコンピューターに文章を学習させるために、わざわざ意味のリストを用意しました。
普通に考えれば、非常に無駄なことではあります。
人間の言葉の仕組みがわかっていない以上仕方のないことですが、
コンピューターが本当に言葉を理解するためには、抜本的な技術の変貌が必要です。

